{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs import SfincsModel\n",
    "from hydromt.config import configread\n",
    "from hydromt.log import setuplog\n",
    "from os.path import join, isfile, isdir\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and data paths\n",
    "model_root = r'../../3_models/SFINCS2'\n",
    "data_libs = [\n",
    "    r'../../1_data/1_static/static_data.yml',\n",
    "    r'../../1_data/2_forcing/forcing_data.yml',    \n",
    "]\n",
    "\n",
    "# NOTE: please contact the autors for an executable\n",
    "fn_exe = \"p:/11205283-hydromt-floodmodelling/02_models/bin/subgrid_openacc_11_rev295_16092021/sfincs.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-06 10:08:49,856 - update - log - DEBUG - Appending log messages to file ../../3_models/SFINCS2\\00_base_100m\\hydromt.log.\n",
      "2024-03-06 10:08:49,857 - update - log - INFO - HydroMT version: 0.4.5\n"
     ]
    }
   ],
   "source": [
    "base_root = join(model_root, \"00_base_100m\")\n",
    "logger = setuplog('update', join(base_root, \"hydromt.log\"), log_level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-06 10:08:52,301 - update - model_api - INFO - Initializing sfincs model from hydromt_sfincs (v0.2.1).\n",
      "2024-03-06 10:08:52,332 - update - model_api - WARNING - Model dir already exists and files might be overwritten: c:\\Users\\pjdeb\\OneDrive\\Documenten\\Universiteit\\CT 5\\MDP\\Git\\MDP\\DirkEilander-compound_flood_modelling-c5285c6\\3_models\\SFINCS2\\00_base_100m\\gis.\n",
      "2024-03-06 10:08:52,334 - update - model_api - DEBUG - Setting model config options.\n",
      "2024-03-06 10:08:52,339 - update - model_api - DEBUG - Default config read from c:\\Users\\pjdeb\\anaconda3\\envs\\compound_hazard\\lib\\site-packages\\hydromt_sfincs\\data\\sfincs\\sfincs.inp\n",
      "2024-03-06 10:08:52,340 - update - model_api - INFO - setup_region.region: {'bbox': [34.33, -20.12, 34.95, -19.3]}\n",
      "2024-03-06 10:08:52,341 - update - model_api - INFO - setup_region.hydrography_fn: merit_hydro\n",
      "2024-03-06 10:08:52,342 - update - model_api - INFO - setup_region.basin_index_fn: merit_hydro_index\n",
      "2024-03-06 10:08:52,344 - update - basin_mask - DEBUG - Parsed region (kind=bbox): {'bbox': [34.33, -20.12, 34.95, -19.3]}\n",
      "2024-03-06 10:08:52,364 - update - model_api - INFO - setup_topobathy.topobathy_fn: merit_hydro\n",
      "2024-03-06 10:08:52,366 - update - model_api - INFO - setup_topobathy.res: 100\n",
      "2024-03-06 10:08:52,368 - update - model_api - INFO - setup_topobathy.crs: utm\n",
      "2024-03-06 10:08:52,369 - update - model_api - INFO - setup_topobathy.reproj_method: bilinear\n",
      "2024-03-06 10:08:52,598 - update - data_adapter - INFO - DataCatalog: Getting merit_hydro RasterDataset raster data from c:\\Users\\pjdeb\\OneDrive\\Documenten\\Universiteit\\CT 5\\MDP\\Git\\MDP\\DirkEilander-compound_flood_modelling-c5285c6\\1_data\\1_static\\merit_hydro\\{variable}.tif\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'xarray' has no attribute 'open_rasterio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m'\u001b[39m,{})\n\u001b[0;32m      6\u001b[0m mod \u001b[38;5;241m=\u001b[39m SfincsModel(root\u001b[38;5;241m=\u001b[39mbase_root, data_libs\u001b[38;5;241m=\u001b[39mdata_libs, logger\u001b[38;5;241m=\u001b[39mlogger, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m mod\u001b[38;5;241m.\u001b[39mplot_basemap()\n",
      "File \u001b[1;32mc:\\Users\\pjdeb\\anaconda3\\envs\\compound_hazard\\lib\\site-packages\\hydromt\\models\\model_api.py:156\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, region, res, write, opt)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    155\u001b[0m         write \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_log_method(method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopt[method])\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# write\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m write:\n",
      "File \u001b[1;32mc:\\Users\\pjdeb\\anaconda3\\envs\\compound_hazard\\lib\\site-packages\\hydromt\\models\\model_api.py:98\u001b[0m, in \u001b[0;36mModel._run_log_method\u001b[1;34m(self, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pjdeb\\anaconda3\\envs\\compound_hazard\\lib\\site-packages\\hydromt_sfincs\\sfincs.py:189\u001b[0m, in \u001b[0;36mSfincsModel.setup_topobathy\u001b[1;34m(self, topobathy_fn, res, crs, reproj_method)\u001b[0m\n\u001b[0;32m    186\u001b[0m         geom \u001b[38;5;241m=\u001b[39m geom\u001b[38;5;241m.\u001b[39mto_crs(crs\u001b[38;5;241m.\u001b[39mto_epsg())\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# read global data (lazy!)\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m da_elv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_catalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rasterdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopobathy_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43melevtn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# reproject to destination CRS\u001b[39;00m\n\u001b[0;32m    194\u001b[0m check_crs \u001b[38;5;241m=\u001b[39m crs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m da_elv\u001b[38;5;241m.\u001b[39mraster\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m!=\u001b[39m crs\n",
      "File \u001b[1;32mc:\\Users\\pjdeb\\anaconda3\\envs\\compound_hazard\\lib\\site-packages\\hydromt\\data_adapter.py:455\u001b[0m, in \u001b[0;36mDataCatalog.get_rasterdataset\u001b[1;34m(self, path_or_key, bbox, geom, buffer, align, variables, time_tuple, single_var_as_array, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msources[name]\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataCatalog: Getting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RasterDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m )\n\u001b[1;32m--> 455\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_var_as_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_var_as_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\pjdeb\\anaconda3\\envs\\compound_hazard\\lib\\site-packages\\hydromt\\data_adapter.py:983\u001b[0m, in \u001b[0;36mRasterDatasetAdapter.get_data\u001b[1;34m(self, bbox, geom, buffer, align, variables, time_tuple, single_var_as_array, logger)\u001b[0m\n\u001b[0;32m    981\u001b[0m     ds_out \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen_raster_from_tindex(fns[\u001b[38;5;241m0\u001b[39m], bbox\u001b[38;5;241m=\u001b[39mbbox, geom\u001b[38;5;241m=\u001b[39mgeom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraster\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# rasterio files\u001b[39;00m\n\u001b[1;32m--> 983\u001b[0m     ds_out \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen_mfraster(fns, logger\u001b[38;5;241m=\u001b[39mlogger, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRasterDataset: Driver \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pjdeb\\anaconda3\\envs\\compound_hazard\\lib\\site-packages\\hydromt\\io.py:141\u001b[0m, in \u001b[0;36mopen_mfraster\u001b[1;34m(paths, chunks, concat, concat_dim, mosaic, mosaic_kwargs, logger, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m da_lst, index_lst, fn_attrs \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(paths):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# read file\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m     da \u001b[38;5;241m=\u001b[39m open_raster(fn, chunks\u001b[38;5;241m=\u001b[39mchunks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# get name, attrs and index (if concat)\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     bname \u001b[38;5;241m=\u001b[39m basename(fn)\n",
      "File \u001b[1;32mc:\\Users\\pjdeb\\anaconda3\\envs\\compound_hazard\\lib\\site-packages\\hydromt\\io.py:54\u001b[0m, in \u001b[0;36mopen_raster\u001b[1;34m(filename, mask_nodata, chunks, nodata, logger, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_raster\u001b[39m(\n\u001b[0;32m     31\u001b[0m     filename, mask_nodata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, chunks\u001b[38;5;241m=\u001b[39m{}, nodata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, logger\u001b[38;5;241m=\u001b[39mlogger, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     32\u001b[0m ):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open a gdal-readable file with rasterio based on :py:meth:`xarray.open_rasterio`\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    and parse geospatial attributes.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m        The newly created DataArray.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     da \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_rasterio\u001b[49m(filename, chunks\u001b[38;5;241m=\u001b[39mchunks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     55\u001b[0m     da \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mreset_coords(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# drop band dimension if single layer\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# additional hydromt.raster parsing\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'xarray' has no attribute 'open_rasterio'"
     ]
    }
   ],
   "source": [
    "# build model base layers\n",
    "region = {'bbox': [34.33,-20.12,34.95,-19.30]}\n",
    "res = 100 # resolution [m]\n",
    "opt = configread('build_sfincs.ini', abs_path=True)\n",
    "kwargs = opt.pop('global',{})\n",
    "mod = SfincsModel(root=base_root, data_libs=data_libs, logger=logger, **kwargs)\n",
    "mod.build(region=region, res=res, opt=opt)\n",
    "mod.plot_basemap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update base model river bathymetry\n",
    "base_root = join(model_root, \"00_base_100m\")\n",
    "runs = [\n",
    "    (1, {'rivdph_method': 'powlaw'}, {}),\n",
    "    (2, {'rivdph_method': 'powlaw', 'hc': 0.405}, {}),  # 1.5x river depth\n",
    "    (2, {'rivdph_method': 'powlaw', 'hc': 0.135}, {}),   # 0.5x river depth\n",
    "    (3, {'rivdph_method': 'powlaw'}, {'lnd_man': 0.15}),  # 1.5x land manning\n",
    "    (3, {'rivdph_method': 'powlaw'}, {'lnd_man': 0.05}),  # 0.5x land manning\n",
    "]\n",
    "# base_root = join(model_root, \"10_base_50m\")\n",
    "# runs = [\n",
    "#     (11, {'rivdph_method': 'powlaw'}),\n",
    "#     (12, {'rivdph_method': 'manning'}),\n",
    "#     (13, {'rivdph_method': 'gvf'}),\n",
    "#     (18, {'rivdph_method': 'powlaw', 'river_upa': 25}),\n",
    "# ]\n",
    "for i, kwargs, kwargs1 in runs:\n",
    "    opt = configread(f'update_rivbathy.ini', abs_path=True)\n",
    "    postfix = '_'.join([f'{k[:3]}{v}' for k,v in kwargs.items()])\n",
    "    root = join(model_root, f'{i:02d}_{postfix}')\n",
    "    if kwargs1:\n",
    "        postfix1 = '_'.join([f'{k[:3]}{v}' for k,v in kwargs1.items()])\n",
    "        root = f'{root}_{postfix1}'\n",
    "    if isfile(join(root, 'sfincs.inp')):\n",
    "        continue\n",
    "    mod1 = SfincsModel(base_root, mode='r', data_libs=data_libs, logger=logger)\n",
    "    # update bathymetry with specific settings\n",
    "    opt['setup_river_bathymetry'].update(kwargs)\n",
    "    opt['setup_manning_roughness'].update(kwargs1)\n",
    "    mod1.update(model_out=root, opt=opt, write=False)\n",
    "    # set zs ini restart file\n",
    "    mask = np.logical_or(mod1.staticmaps['rivmsk']==1, mod1.staticmaps['dep']<0)\n",
    "    zsini = mod1.staticmaps['dep'].where(~mask, np.maximum(mod1.staticmaps['dep']+0.2, 0.5)).where(mod1.mask!=0,0)\n",
    "    zsini.raster.set_nodata(0)\n",
    "    mod1.set_states(zsini, 'zsini')\n",
    "    mod1.config.pop('zsini',None)\n",
    "    # write static maps, states and config\n",
    "    mod1.write()\n",
    "    mod1.plot_basemap(geoms=[])\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write forcing for idai / eloise\n",
    "runs = [r for r in glob.glob(f'{model_root}/*_rivpowlaw_*') if not isfile(r)]\n",
    "for root0 in runs:\n",
    "    # update forcing in subfolders\n",
    "    for event in ['idai', 'eloise']:\n",
    "        root = join(root0, event)\n",
    "        if isfile(join(root, 'sfincs.inp')):\n",
    "            continue\n",
    "        mod1 = SfincsModel(root0, mode='r', data_libs=data_libs, logger=logger)\n",
    "        opt = configread(f'update_sfincs_{event}.ini', abs_path=True)\n",
    "        mod1.update(model_out=root, opt=opt, write=False)\n",
    "        # write forcing and sfincs.inp only\n",
    "        mod1.write_forcing()\n",
    "        mod1.write_config(rel_path=f'../')\n",
    "        mod1.plot_forcing()\n",
    "        plt.close('all')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write forcing for sensitivity analysis\n",
    "runs = [r for r in glob.glob(f'{model_root}/*') if not isfile(r)]\n",
    "base_root = join(model_root, \"01_rivpowlaw\")\n",
    "\n",
    "# update forcing in subfolders\n",
    "for event in ['idai', 'eloise']:\n",
    "    for run in ['glofas', 'h_x80', 'h_x120', 'qp_x80', 'qp_x120']:\n",
    "        root = join(base_root, f'{event}_{run}')\n",
    "        if isfile(join(root, 'sfincs.inp')):\n",
    "            continue\n",
    "        mod1 = SfincsModel(base_root, mode='r', data_libs=data_libs, logger=logger)\n",
    "        opt = configread(f'update_sfincs_{event}.ini', abs_path=True)\n",
    "        # glofas forcing only with default 01_ run\n",
    "        if 'glofas' in run:\n",
    "            opt['setup_q_forcing_from_grid'].update({\n",
    "                'discharge_fn': 'glofas_era5', 'uparea_fn': 'glofas_uparea'\n",
    "            })\n",
    "        elif 'qp_' in run:\n",
    "            mult = run.split('_')[1]\n",
    "            dis_fn = opt['setup_q_forcing_from_grid']['discharge_fn']\n",
    "            opt['setup_q_forcing_from_grid'].update({'discharge_fn': f'{dis_fn}_{mult}'})\n",
    "            prec_fn = opt['setup_p_forcing_from_grid']['precip_fn']\n",
    "            opt['setup_p_forcing_from_grid'].update({'precip_fn': f'{prec_fn}_{mult}'})\n",
    "        elif 'h_' in run:\n",
    "            mult = run.split('_')[1]\n",
    "            h_fn = opt['setup_h_forcing']['geodataset_fn']\n",
    "            opt['setup_h_forcing'].update({'geodataset_fn': f'{h_fn}_{mult}'})\n",
    "        mod1.update(model_out=root, opt=opt, write=False)\n",
    "        # write forcing and sfincs.inp only\n",
    "        mod1.write_forcing()\n",
    "        mod1.write_config(rel_path=f'../')\n",
    "        mod1.plot_forcing()\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs.utils import write_timeseries, write_inp\n",
    "import os\n",
    "## prepare compound runs\n",
    "\n",
    "base_root = join(model_root, \"01_rivpowlaw\")\n",
    "base_root = join(model_root, \"02_rivpowlaw_hc0.405\")\n",
    "for event in ['idai', 'eloise']:\n",
    "    mod = SfincsModel(join(base_root, event), mode='r', data_libs=data_libs)\n",
    "    config = mod.config.copy()\n",
    "    tref = config['tref']\n",
    "\n",
    "    # get htide\n",
    "    htot = mod.forcing['bzs'].copy()\n",
    "    mod.setup_h_forcing(\n",
    "        geodataset_fn = f'gtsm_{event}_tides',   # waterlevel timeseries dataset\n",
    "    )\n",
    "    htide = mod.forcing['bzs'].copy()\n",
    "    assert np.all(htide.vector.xcoords.round(0) == htot.vector.xcoords.round(0))\n",
    "    assert np.all(htide.vector.ycoords.round(0) == htot.vector.ycoords.round(0))\n",
    "\n",
    "    da_dis = mod.forcing['dis'].copy()\n",
    "    # get discharge climatology\n",
    "    # NOTE: requires long series which is not added to the repos; use hardcoded values here\n",
    "    # mod.setup_config(**{\n",
    "    #     'tref': '19900101 000000',\n",
    "    #     'tstart': '19900101 000000',\n",
    "    #     'tstop': '20201231 000000',\n",
    "    # })\n",
    "    # mod.setup_q_forcing_from_grid(\n",
    "    #     discharge_fn = 'cmf_outflw_06min',   # TODO change to 3min version\n",
    "    #     uparea_fn = 'cmf_uparea_06min',   \n",
    "    # )\n",
    "    # da_dis_long = mod.forcing['dis'].copy()\n",
    "    # qmean = da_dis_long.groupby('time.quarter').mean().sel(quarter=int(np.mean(da_dis.time.dt.quarter)))\n",
    "    # qmean = da_dis_long.groupby('time.month').mean().sel(month=int(np.mean(da_dis.time.dt.month)))\n",
    "    # qmean = da_dis_long.mean('time')\n",
    "    # print(qmean.values)\n",
    "    qmean = xr.DataArray(dims='index', data=np.array([161.7727,0.7046502,0.44472486,4.4982467,3.2484558,96.676094,20.92196], dtype=np.float32), )\n",
    "    fact = np.minimum(1,qmean/da_dis.mean())\n",
    "    print(fact.values)\n",
    "    da_disclim = da_dis*fact\n",
    "\n",
    "    qs = {\n",
    "        'disclim': da_disclim.reset_coords(drop=True).to_series().unstack(0),\n",
    "        'dis': da_dis.reset_coords(drop=True).to_series().unstack(0), \n",
    "    }\n",
    "    hs = {\n",
    "        'htide': htide.reset_coords(drop=True).to_series().unstack(0),\n",
    "        'htot': htot.reset_coords(drop=True).to_series().unstack(0),\n",
    "    }\n",
    "    ps = {\n",
    "        'noprecip': None,\n",
    "        'precip': mod.forcing['netampr'].copy(),\n",
    "    }\n",
    "    cmpd_runs = {\n",
    "        'q': ['dis', 'htide', 'noprecip'],\n",
    "        'h': ['disclim', 'htot', 'noprecip'],\n",
    "        'p': ['disclim', 'htide', 'precip'],\n",
    "        # 'base': ['disclim', 'htide', 'noprecip'],\n",
    "        # 'qh': ['dis', 'htot', 'noprecip'],\n",
    "        }\n",
    "    for run, (q, h, p) in cmpd_runs.items():\n",
    "        root = join(base_root, f'{event}_{run}')\n",
    "        if not os.path.isdir(root):\n",
    "            os.makedirs(root)\n",
    "        else:\n",
    "            continue\n",
    "        print(f'{event}_{run}')\n",
    "\n",
    "        shutil.copyfile(join(base_root, event, 'sfincs.src'), join(root, 'sfincs.src'))\n",
    "        write_timeseries(join(root, 'sfincs.dis'), qs[q], tref)\n",
    "        shutil.copyfile(join(base_root, event, 'sfincs.bnd'), join(root, 'sfincs.bnd'))\n",
    "        write_timeseries(join(root, 'sfincs.bzs'), hs[h], tref)\n",
    "        \n",
    "        config1 = config.copy()\n",
    "        if ps[p] is None:\n",
    "            config1.pop('netamprfile')\n",
    "        else:\n",
    "            try:\n",
    "                ps[p].to_netcdf(join(root, 'precip.nc'))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        write_inp(join(root, 'sfincs.inp'), config1)\n",
    "\n",
    "        mod1 = SfincsModel(root, mode='r')\n",
    "        mod1.plot_forcing()\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run models\n",
    "from os.path import dirname\n",
    "\n",
    "def check_finished(root):\n",
    "    finished = False\n",
    "    if isfile(join(root, 'sfincs.log')):\n",
    "        with open(join(root, 'sfincs.log'), 'r') as f:\n",
    "            finished = np.any(['Simulation is finished' in l for l in f.readlines()])\n",
    "    return finished\n",
    "\n",
    "runs = [dirname(fn) for fn in glob.glob(join(model_root, '*', '*', 'sfincs.inp')) if not check_finished(dirname(fn))]\n",
    "n = len(runs)\n",
    "print(n)\n",
    "for i, root in enumerate(runs):\n",
    "    print(f'{i+1:d}/{n:d}: {root}')\n",
    "    with open(join(root, \"sfincs.log\"), 'w') as f:\n",
    "        p = subprocess.Popen([fn_exe], stdout=f, cwd=root)\n",
    "        %time p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('compound_hazard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fb41f7d3c9d44edbd7f9d2eb0da8e67c67759afdf54e6c06938bd0d90c16cc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
