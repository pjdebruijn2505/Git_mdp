{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRA station processing\n",
    "This notebook analyses the Excel file provided to us by the WRA staff. Multiple stations had some inconsistent formatting of the sheets, so this notebook first resolves the format of the Excel format. The discharge and water level measurements are then matched together based on the time of their recording. \n",
    "\n",
    "The next step would be to calculate the discharge for each water level based on the available datapoints. However, the data that is available for stations is rather limited, so some more measurements may need to be done first. \n",
    "\n",
    "After processing each station is saved as a .csv file in the directory with the name of the station as the file name for easy identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os.path\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first entry is pointing to /Users/matskerver/Documents/data_tana/WRA/Garissa_station, the second one to /Users/matskerver/Documents/data_tana/WRA/other_stations and\n"
     ]
    }
   ],
   "source": [
    "# If errors occur here please refer to the readme file or to the file_imports.py folders. \n",
    "\n",
    "cwd = pathlib.Path().resolve()\n",
    "src = cwd.parent\n",
    "data = src.parent.parent.parent\n",
    "root = src.parent\n",
    "sys.path.append(str(src))\n",
    "sys.path.append(str(root))\n",
    "from utils.file_imports import *\n",
    "\n",
    "\n",
    "data_paths = file_paths(root, WRA = True)\n",
    "waterlevel_files = data_paths[1]\n",
    "\n",
    "path = os.path.join(waterlevel_files, 'Tana_data.xlsx')\n",
    "sheet = pd.ExcelFile(path)\n",
    "sheetlist = sheet.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the name of the station, as this is not contained in the sheet name but rather in the first\n",
    "# column of the excel sheet itself. \n",
    "\n",
    "def get_station_name(df):\n",
    "    column_index = 1\n",
    "    column_names = df.columns.tolist()\n",
    "    column_name = column_names[column_index]\n",
    "    parts = column_name.split('-')\n",
    "    extracted_name = parts[0].strip()  \n",
    "    return extracted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4BD01 MATHIOYA', '4BC04 RWAMUTHAMBI', '4BE10 TANA RUKANGA', '4BB01 RAGATI', '4AC03 SAGANA', '4AA05 SAGANA', '4AB06 AMBONI', '4AC04 NEW CHANIA', '4AA04 NAIROBI', '4AA02 THEGO', '4AA01 SAGANA', '4AB01 MURINGATO', '4BC05 RWAMUTHAMBI', '4BE04 KAYAHWE', '4CB04 THIKA', '4BF01 SABA SABA', '4AD01 GURA', '4BD07 MATHIOYA', '4BE01 MARAGUA', '4CA03 CHANIA', '4CA19 KARIMINU', '4DA14 KAMWETI', '4DA13 KIRINGA', '4DB05 NYAMINDI', '4DA10 THIBA', '4BC05 RWAMUTHAMBI', '4DD02 THIBA', '4EA03 KITHINO RIVER']\n"
     ]
    }
   ],
   "source": [
    "# Save all the station names in a single array for naming of the .csv files later.\n",
    "\n",
    "names_stations = []\n",
    "for name in sheetlist:    \n",
    "    df = sheet.parse(name)\n",
    "    names_stations.append(get_station_name(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the sheets to format them properly and save them to a .csv file.\n",
    "\n",
    "for i in range(0, len(sheetlist)):\n",
    "    \n",
    "    # Read the excel file for the current sheet and create a dataframe that will later be converted to .csv\n",
    "    df = pd.read_excel(path, sheet_name=sheetlist[i])\n",
    "    columns_to_drop = [2, 3, 4]  \n",
    "    df = df.drop(df.columns[columns_to_drop], axis=1)\n",
    "    df.columns = [\n",
    "        \"waterlevel(m)\" if i == 1 else\n",
    "        \"Time_Q\" if i == 2 else\n",
    "        \"discharge(m3/s)\" if i == 3 else col\n",
    "        for i, col in enumerate(df.columns)\n",
    "    ]\n",
    "    \n",
    "    # These lines resolve the inconsistent datetime formatting of the dataset. \n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='mixed')\n",
    "    df['Time_Q'] = pd.to_datetime(df['Time_Q'], format='mixed')\n",
    "\n",
    "    # Drop empty cells out of the dataframe\n",
    "    df_level = df.iloc[:,0:2].dropna()\n",
    "    df_discharge = df.iloc[:,2:4].dropna()\n",
    "    df_discharge = df_discharge.rename(columns={\"Time_Q\": \"Time\"})\n",
    "\n",
    "    # Match the discharge data with the water level data where available. Tolerance to be changed based on \n",
    "    # nature of river/stream and the required accuracy.\n",
    "    merged_dataframe = pd.merge_asof(df_level, df_discharge, on=\"Time\", tolerance=pd.Timedelta(\"1days\"))\n",
    "    merged_dataframe.head()\n",
    "    \n",
    "    #Save each file to a .csv file\n",
    "    save_path = os.path.join(waterlevel_files, f\"Tana_station_{names_stations[i]}.csv\")\n",
    "    merged_dataframe.to_csv(save_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
