{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c611d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os.path\n",
    "import pathlib\n",
    "import platform \n",
    "import json \n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import matplotlib as mpl\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.enums import Resampling\n",
    "import imageio.v2 as imageio\n",
    "import xarray as xr\n",
    "import sys\n",
    "from rasterio import features\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8b210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first entry is pointing to /Users/matskerver/Documents/data_tana/TAHMO/raw_TAHMO, the second one to /Users/matskerver/Documents/data_tana/TAHMO/processed_TAHMO and the third one to /Users/matskerver/Documents/data_tana/TAHMO/interpolated_TAHMO. Animations will be put located in /Users/matskerver/Documents/data_tana/TAHMO/results\n"
     ]
    }
   ],
   "source": [
    "# If errors occur here please refer to the readme file or to the file_imports.py folders. \n",
    "\n",
    "cwd = pathlib.Path().resolve()\n",
    "src = cwd.parent\n",
    "data = src.parent.parent.parent\n",
    "root = src.parent\n",
    "OS_type = platform.system()\n",
    "sys.path.append(str(src))\n",
    "sys.path.append(str(root))\n",
    "from utils.file_imports import *\n",
    "\n",
    "\n",
    "data_paths = file_paths(root, TAHMO = True)\n",
    "shape_raw = data_paths[0]\n",
    "raw_files = data_paths[1]\n",
    "processed_files = data_paths[2]\n",
    "animation_path = data_paths[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_file = 'NetCDF_TAHMO.nc'\n",
    "ds = xr.open_dataset(os.path.join(raw_files, netcdf_file))\n",
    "\n",
    "# Load geographical data\n",
    "proj = 'EPSG:32737'\n",
    "counties = gpd.read_file(os.path.join(shape_raw, 'total_tana_catchement_area_clip_projected.gpkg'))\n",
    "\n",
    "# Variables for plotting\n",
    "variable = 'te_mean'\n",
    "\n",
    "geo_dataframes = {}\n",
    "for station in ds.data_vars:\n",
    "    # Extract longitude and latitude for each station\n",
    "    # Assume longitude and latitude are constant over time; thus, we take the mean\n",
    "    longitude = ds[station].sel(variable='longitude').mean().values.item()\n",
    "    latitude = ds[station].sel(variable='latitude').mean().values.item()\n",
    "\n",
    "    # Select the data for the variable of interest and create a geoDataframe with this variable\n",
    "    df = ds[station].sel(variable=variable).to_dataframe().reset_index()\n",
    "    point = Point(longitude, latitude)\n",
    "    rain_gdf = gpd.GeoDataFrame(df, geometry=[point] * len(df), crs=proj)\n",
    "    geo_dataframes[station] = rain_gdf\n",
    "\n",
    "# Use standard procedure to plot the Tana basin \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plt.style.use('bmh')\n",
    "counties.plot(ax=ax, color='bisque', edgecolor='dimgray')\n",
    "\n",
    "for key, gdf in geo_dataframes.items():\n",
    "    gdf.plot(ax=ax, marker='o', color='red', markersize=15)\n",
    "\n",
    "ax.set_title('Tana Basin Area Kenya', fontdict={'fontsize': '15', 'fontweight': '3'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Warning! creates a file of multiple gb (about 6.5Gb for grid_space = 0.01)\n",
    "netCDF_file = True \n",
    "\n",
    "if (netCDF_file == True):\n",
    "    \n",
    "    #Reads in the required datasets and shapefiles to use the Kriging interpolation on.\n",
    "    ds = xr.open_dataset(os.path.join(raw_files, 'NetCDF_TAHMO.nc'))\n",
    "    path_shape = os.path.join(shape_raw, 'total_tana_catchement_area_clip.shp')\n",
    "    shapefile = gpd.read_file(path_shape)\n",
    "    \n",
    "    #Variables that determine the grid resolution (in degrees longitude and latitude) and the extend of the earth \n",
    "    #to be plotted (same units).\n",
    "    grid_space = 0.05\n",
    "    variable = 'evap'\n",
    "    longitudes_mapped = [36, 42]\n",
    "    latitudes_mapped = [-4, 2]\n",
    "    \n",
    "    \n",
    "    grid_lons = np.arange(longitudes_mapped[0], longitudes_mapped[1], grid_space)\n",
    "    grid_lats = np.arange(latitudes_mapped[0], latitudes_mapped[1], grid_space)\n",
    "\n",
    "    #Extract the station, location and variable data from the dataset ds\n",
    "    latitudes = ds.sel(variable='latitude').to_array().mean(dim='time').values\n",
    "    longitudes = ds.sel(variable='longitude').to_array().mean(dim='time').values\n",
    "    station_ids = ds.sel(variable='latitude').to_array().mean(dim='time').coords['variable'].values\n",
    "    variable_data = ds.sel(variable=variable)\n",
    "\n",
    "    # Create empty variable to store the grids in and a variable to keep track of the progress of the interpolation.\n",
    "    # Variable interval determines the timesteps on which the progess will be printed.\n",
    "    z_values = []\n",
    "    progress = 0\n",
    "    interval = 100\n",
    "    total_steps = len(ds.time)\n",
    "    \n",
    "    \n",
    "    # ------------- Don't Change anything beneath this line. Variables should be changed above -------------- #\n",
    "\n",
    "    \n",
    "    #We loop through each of the timesteps in the provided netcdf file.\n",
    "    for time_value in ds.time:\n",
    "        \n",
    "        #Empty array is created to store the current data variable to be interpolated on the grid\n",
    "        data = []\n",
    "        for station in ds.data_vars:\n",
    "            # Select the data for the current time and variable of interest\n",
    "            value = ds[station].sel(time=time_value, variable=variable).values\n",
    "            data.append(value.item() if value.size > 0 else np.nan)\n",
    "        \n",
    "        # Convert the data to a numpy array so we can apply a mask. As some stations have gaps in their data we \n",
    "        # need to exclude these to prevent errors. This is done with the Mask. We also need to remove the longitudes\n",
    "        # and latitudes of these points to ensure consistent array dimensions. \n",
    "        \n",
    "        data = np.array(data)\n",
    "        valid_mask = ~np.isnan(data)\n",
    "        filtered_data = data[valid_mask]\n",
    "        filtered_longitudes = longitudes[valid_mask]\n",
    "        filtered_latitudes = latitudes[valid_mask]\n",
    "\n",
    "        # Setup the Ordinary Kriging interpolator and subsequently execute it. It is then added to the array.\n",
    "        OK = OrdinaryKriging(\n",
    "            filtered_longitudes,\n",
    "            filtered_latitudes,\n",
    "            filtered_data,\n",
    "            variogram_model='gaussian',\n",
    "            verbose=False,\n",
    "            enable_plotting=False\n",
    "        )\n",
    "        z, ss = OK.execute('grid', grid_lons, grid_lats)\n",
    "        z_values.append(z)\n",
    "        \n",
    "        # Keep the user updated on the progress of the interpolation process as it can take some time.\n",
    "        if (progress % interval == 0):\n",
    "            print(f'Update: {progress}/{total_steps} succesfully processed.')\n",
    "        progress += 1\n",
    "\n",
    "        \n",
    "    # Put all the data back into a suitable Xarray to be converted into the final NetCDF file\n",
    "    z_array = np.stack(z_values)\n",
    "\n",
    "    time_dim = ds.time \n",
    "    lon_dim = np.arange(longitudes_mapped[0], longitudes_mapped[1], grid_space)  # Longitude grid\n",
    "    lat_dim = np.arange(latitudes_mapped[0], latitudes_mapped[1], grid_space)  # Latitude grid\n",
    "    kriging_ds = xr.Dataset(\n",
    "        {\n",
    "            variable: (['time', 'latitude', 'longitude'], z_array)\n",
    "        },\n",
    "        coords={\n",
    "            'time': time_dim,\n",
    "            'latitude': lat_dim,\n",
    "            'longitude': lon_dim\n",
    "        }\n",
    "    )\n",
    "\n",
    "    kriging_ds.to_netcdf(os.path.join(processed_files, 'kriging_results_evap.nc'))\n",
    "    print(f'file succesfully saved at {processed_files}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f80124",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = True\n",
    "\n",
    "if animation:\n",
    "\n",
    "    # Scale of the plot and a custom colormapping. Change vmin and vmax for other variables\n",
    "    # to suitable values. \n",
    "    \n",
    "    vmin = 0.3\n",
    "    vmax = 0.6\n",
    "    cdict = {\n",
    "            'red':   [(0.0, 1.0, 1.0), (0.05, 0.59, 0.59), (1.0, 0.0, 0.0)],\n",
    "            'green': [(0.0, 1.0, 1.0), (0.05, 0.29, 0.29), (0.2, 1.0, 1.0), (1.0, 0.0, 0.0)],\n",
    "            'blue':  [(0.0, 0.88, 0.88), (0.05, 0.1, 0.1), (0.2, 1.0, 1.0), (1.0, 1.0, 1.0)]\n",
    "        }\n",
    "\n",
    "    cm = mpl.colors.LinearSegmentedColormap('my_colormap', cdict, 1024)\n",
    "\n",
    "    # Load the dataset created in the previous cell and determine the required output (variable and timesteps)\n",
    "    netcdf_file_raster = 'kriging_results_evap.nc'\n",
    "    ds = xr.open_dataset(os.path.join(processed_files, netcdf_file_raster))\n",
    "    variable = 'evap'\n",
    "    time_indices = range(0, ds.dims['time'], 1)  \n",
    "    file_paths = []\n",
    "\n",
    "    # Open the shapefile that the kriging interpolation will be clipped on.\n",
    "    path_shape = os.path.join(shape_raw, 'total_tana_catchement_area_clip.shp')\n",
    "    shapefile_gdf = gpd.read_file(path_shape)\n",
    "\n",
    "\n",
    "    for time_index in time_indices:\n",
    "        selected_data = ds.isel(time=time_index)\n",
    "        data_array = selected_data[variable]\n",
    "\n",
    "        # Generate raster to plot upon\n",
    "        grid_lons, grid_lats = ds['longitude'].values, ds['latitude'].values\n",
    "        grid_space = grid_lons[1] - grid_lons[0]\n",
    "        transform = rasterio.transform.from_origin(min(grid_lons), max(grid_lats), grid_space, grid_space)\n",
    "        temp_tif = 'temp.tif'\n",
    "        with rasterio.open(\n",
    "            temp_tif, 'w', driver='GTiff',\n",
    "            height=data_array.shape[0], width=data_array.shape[1],\n",
    "            count=1, dtype=str(data_array.dtype),\n",
    "            crs='+proj=latlong',\n",
    "            transform=transform\n",
    "        ) as raster:\n",
    "            raster.write(data_array.values, 1)\n",
    "\n",
    "        # Clip raster to the previously opened shapefile so the Tana Basin is correctly represented. \n",
    "        with rasterio.open(temp_tif) as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, shapefile_gdf.geometry, crop=True)\n",
    "            out_meta = src.meta.copy()\n",
    "\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "\n",
    "        clipped_tif = 'clipped.tif'\n",
    "        with rasterio.open(clipped_tif, 'w', **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "\n",
    "        # Create plots of the result that will be saved as .png\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        with rasterio.open(clipped_tif) as raster_plot:\n",
    "            img_array = raster_plot.read(1)\n",
    "            extent = [out_transform[2], out_transform[2] + out_transform[0] * img_array.shape[1],\n",
    "                      out_transform[5] + out_transform[4] * img_array.shape[0], out_transform[5]]\n",
    "\n",
    "            img = ax.imshow(img_array, extent=extent, cmap=cm, origin='upper', vmin=vmin, vmax=vmax)  \n",
    "            ax.set_title(f'{variable} on {selected_data.time.dt.strftime(\"%Y-%m-%d\").values}')\n",
    "            ax.set_xlabel('Longitude')\n",
    "            ax.set_ylabel('Latitude')\n",
    "\n",
    "            cbar = fig.colorbar(img, ax=ax)\n",
    "            cbar.set_label(variable)\n",
    "\n",
    "        # Save the plot and save all the file names to an array.\n",
    "        image_filename = f'image_{time_index}.png'\n",
    "        plt.savefig(os.path.join(animation_path, image_filename))\n",
    "        plt.close()\n",
    "        file_paths.append(image_filename)\n",
    "\n",
    "\n",
    "    gif_filename = f'time_series_{variable}.gif'  \n",
    "    with imageio.get_writer(os.path.join(animation_path, gif_filename), mode='I', duration=0.5) as writer:\n",
    "        for filename in file_paths:\n",
    "            image = imageio.imread(os.path.join(animation_path, filename))\n",
    "            writer.append_data(image)  # Pass the image data array directly\n",
    "\n",
    "    # Delete the individual image files after creating the GIF\n",
    "    for filename in file_paths:\n",
    "        os.remove(os.path.join(animation_path, filename))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
