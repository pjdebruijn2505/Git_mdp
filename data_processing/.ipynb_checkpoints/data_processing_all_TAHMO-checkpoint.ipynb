{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os.path\n",
    "import pathlib\n",
    "import platform \n",
    "import json \n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome Mats , have a wondeful day on your Darwin machine. Your data should be located in /Users/matskerver/Documents/data_tana/TAHMO\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path().resolve()\n",
    "src = cwd.parent\n",
    "data = src.parent.parent.parent\n",
    "OS_type = platform.system()\n",
    "\n",
    "if OS_type == 'Darwin':\n",
    "    username = 'Mats '\n",
    "    data_path = os.path.join(data, 'data_tana', 'TAHMO')\n",
    "    \n",
    "else:\n",
    "    username = 'Mootje'\n",
    "    data_path = os.path.join(data, 'OneDrive - Delft University of Technology', 'TU Delft', 'Master ENVM', 'MDP', 'Model', 'Data', 'TAHMO')\n",
    "\n",
    "print(f\"Welcome {username}, have a wondeful day on your {OS_type} machine. Your data should be located in {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/6366qhx54w16_p3_07s3n5ym0000gn/T/ipykernel_56528/373269495.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(file, index_col = 0, sep =',', parse_dates = True)\n"
     ]
    }
   ],
   "source": [
    "data_files = glob.glob(os.path.join(data_path, '*.csv'))\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for file in data_files:\n",
    "    station_name = os.path.splitext(os.path.basename(file))[0].split('_')[0]\n",
    "    df = pd.read_csv(file, index_col = 0, sep =',', parse_dates = True)\n",
    "    dataframes[station_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>te</th>\n",
       "      <th>pr</th>\n",
       "      <th>ra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-16 08:15:00</th>\n",
       "      <td>27.4</td>\n",
       "      <td>0.017</td>\n",
       "      <td>834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16 08:20:00</th>\n",
       "      <td>27.3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16 08:25:00</th>\n",
       "      <td>27.3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16 08:30:00</th>\n",
       "      <td>27.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16 08:35:00</th>\n",
       "      <td>27.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30 23:40:00</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30 23:45:00</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30 23:50:00</th>\n",
       "      <td>22.3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30 23:55:00</th>\n",
       "      <td>22.3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 00:00:00</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608694 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       te     pr     ra\n",
       "Timestamp                              \n",
       "2018-03-16 08:15:00  27.4  0.017  834.0\n",
       "2018-03-16 08:20:00  27.3  0.000  643.0\n",
       "2018-03-16 08:25:00  27.3  0.000  805.0\n",
       "2018-03-16 08:30:00  27.2  0.000  728.0\n",
       "2018-03-16 08:35:00  27.2  0.000  676.0\n",
       "...                   ...    ...    ...\n",
       "2023-12-30 23:40:00  22.4  0.000    0.0\n",
       "2023-12-30 23:45:00  22.4  0.000    0.0\n",
       "2023-12-30 23:50:00  22.3  0.000    0.0\n",
       "2023-12-30 23:55:00  22.3  0.000    0.0\n",
       "2023-12-31 00:00:00  22.4  0.000    0.0\n",
       "\n",
       "[608694 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['TA00023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TA00360', 'TA00080', 'TA00166', 'location']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_keys = []\n",
    "\n",
    "# Iterate over each key, df pair in the dictionary\n",
    "for key, df in dataframes.items():\n",
    "    # Check if 'te' and 'pr' columns are present in the dataframe\n",
    "    if 'te' not in df.columns or 'pr' not in df.columns:\n",
    "        # Add the key to the list of invalid keys\n",
    "        invalid_keys.append(key)\n",
    "\n",
    "invalid_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>te_S001384</th>\n",
       "      <th>te_S000824</th>\n",
       "      <th>te_S000823</th>\n",
       "      <th>pr_S001384</th>\n",
       "      <th>pr_S000824</th>\n",
       "      <th>pr_S000822</th>\n",
       "      <th>ra_S001384</th>\n",
       "      <th>ra_S000820</th>\n",
       "      <th>ra_S000824</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:15:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:20:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30 23:40:00</th>\n",
       "      <td>16.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30 23:45:00</th>\n",
       "      <td>16.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30 23:50:00</th>\n",
       "      <td>16.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30 23:55:00</th>\n",
       "      <td>16.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 00:00:00</th>\n",
       "      <td>16.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578800 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     te_S001384  te_S000824  te_S000823  pr_S001384  \\\n",
       "Timestamp                                                             \n",
       "2018-01-01 00:00:00         NaN         NaN        13.2         NaN   \n",
       "2018-01-01 00:05:00         NaN         NaN        13.0         NaN   \n",
       "2018-01-01 00:10:00         NaN         NaN        13.0         NaN   \n",
       "2018-01-01 00:15:00         NaN         NaN        12.9         NaN   \n",
       "2018-01-01 00:20:00         NaN         NaN        12.8         NaN   \n",
       "...                         ...         ...         ...         ...   \n",
       "2023-12-30 23:40:00        16.9         NaN         NaN         NaN   \n",
       "2023-12-30 23:45:00        16.9         NaN         NaN         NaN   \n",
       "2023-12-30 23:50:00        16.9         NaN         NaN         NaN   \n",
       "2023-12-30 23:55:00        16.9         NaN         NaN         NaN   \n",
       "2023-12-31 00:00:00        16.8         NaN         NaN         NaN   \n",
       "\n",
       "                     pr_S000824  pr_S000822  ra_S001384  ra_S000820  \\\n",
       "Timestamp                                                             \n",
       "2018-01-01 00:00:00         NaN         NaN         NaN         0.0   \n",
       "2018-01-01 00:05:00         NaN         NaN         NaN         0.0   \n",
       "2018-01-01 00:10:00         NaN         NaN         NaN         0.0   \n",
       "2018-01-01 00:15:00         NaN         NaN         NaN         0.0   \n",
       "2018-01-01 00:20:00         NaN         NaN         NaN         0.0   \n",
       "...                         ...         ...         ...         ...   \n",
       "2023-12-30 23:40:00         NaN         NaN         0.0         NaN   \n",
       "2023-12-30 23:45:00         NaN         NaN         0.0         NaN   \n",
       "2023-12-30 23:50:00         NaN         NaN         0.0         NaN   \n",
       "2023-12-30 23:55:00         NaN         NaN         0.0         NaN   \n",
       "2023-12-31 00:00:00         NaN         NaN         0.0         NaN   \n",
       "\n",
       "                     ra_S000824  \n",
       "Timestamp                        \n",
       "2018-01-01 00:00:00         NaN  \n",
       "2018-01-01 00:05:00         NaN  \n",
       "2018-01-01 00:10:00         NaN  \n",
       "2018-01-01 00:15:00         NaN  \n",
       "2018-01-01 00:20:00         NaN  \n",
       "...                         ...  \n",
       "2023-12-30 23:40:00         NaN  \n",
       "2023-12-30 23:45:00         NaN  \n",
       "2023-12-30 23:50:00         NaN  \n",
       "2023-12-30 23:55:00         NaN  \n",
       "2023-12-31 00:00:00         NaN  \n",
       "\n",
       "[578800 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['TA00080']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset from WRA contained three files with strange formatting, presumably due to an error with the API \n",
    "# This snipped solves the individual dataframes after manual inspection. For implementation with more stations \n",
    "# it is recommended to contact TAHMO or skip these 'faulty' stations \n",
    "\n",
    "if dataframes['TA00080'].shape[1] == 9: # This contains three values for each te, pr, ra, two of which are NaN\n",
    "    dataframes['TA00080'].columns = ['te_1', 'te_2', 'te_3', 'pr_1', 'pr_2', 'pr_3', 'ra_1', 'ra_2', 'ra_3']\n",
    "    dataframes['TA00080'] = dataframes['TA00080'].fillna(0.0)\n",
    "    dataframes['TA00080']['te'] = dataframes['TA00080'].iloc[:, :3].sum(axis=1) #summed to fill the columns\n",
    "    dataframes['TA00080']['pr'] = dataframes['TA00080'].iloc[:, 3:6].sum(axis=1)\n",
    "    dataframes['TA00080']['ra'] = dataframes['TA00080'].iloc[:, 6:9].sum(axis=1)\n",
    "    dataframes['TA00080'] = dataframes['TA00080'].iloc[:, 9:]  #Remove the faulty columns\n",
    "    \n",
    "if dataframes['TA00360'].shape[1] == 6: #similar to above\n",
    "    dataframes['TA00360'].columns = ['te_1', 'te_2', 'pr_1', 'pr_2', 'ra_1', 'ra_2']\n",
    "    dataframes['TA00360']['te'] = dataframes['TA00360'].iloc[:, :2].sum(axis=1)\n",
    "    dataframes['TA00360']['pr'] = dataframes['TA00360'].iloc[:, 2:4].sum(axis=1)\n",
    "    dataframes['TA00360']['ra'] = dataframes['TA00360'].iloc[:, 4:6].sum(axis=1)\n",
    "    dataframes['TA00360'] = dataframes['TA00360'].iloc[:, 6:]\n",
    "    \n",
    "if dataframes['TA00166'].shape[1] == 9: #similar to above\n",
    "    dataframes['TA00166'].columns = ['te_1', 'te_2', 'te_3', 'pr_1', 'pr_2', 'pr_3', 'ra_1', 'ra_2', 'ra_3']\n",
    "    dataframes['TA00166']['te'] = dataframes['TA00166'].iloc[:, :3].sum(axis=1)\n",
    "    dataframes['TA00166']['pr'] = dataframes['TA00166'].iloc[:, 3:6].sum(axis=1)\n",
    "    dataframes['TA00166']['ra'] = dataframes['TA00166'].iloc[:, 6:9].sum(axis=1)\n",
    "    dataframes['TA00166'] = dataframes['TA00166'].iloc[:, 9:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extra_rad(Tmax, Tmin, df, lat):\n",
    "    \"Calculation of Extraterrestrial radiation\"\n",
    "    G = 0.0820 #* 10 ** 6 # J/m^2/min  --> Constant value\n",
    "\n",
    "    # Calculation of the radian location of the station\n",
    "    phi = np.pi / 180 * lat\n",
    "\n",
    "    # Calculation of the number of the day in a year\n",
    "    J = df.index.dayofyear.values  # Extract day of the year directly from the index\n",
    "\n",
    "    # Calculation of the extraterrestrial radiation: Ra\n",
    "    dr = 1 + 0.033 * np.cos(2 * np.pi * J / 365)\n",
    "    delta = 0.409 * np.sin((2 * np.pi * J / 365) - 1.39)\n",
    "    w = np.arccos(- np.tan(phi) * np.tan(delta))\n",
    "    Ra = ((24 * 60) / np.pi) * G * dr * (w * np.sin(phi) * np.sin(delta) + np.cos(phi) * np.cos(delta) * np.sin(w)) #* 10 ** - 6\n",
    "\n",
    "    # Create a DataFrame with Ra values and corresponding timestamps\n",
    "    Ra_df = pd.DataFrame({'Ra': Ra}, index=df.index)\n",
    "\n",
    "    return Ra_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df):\n",
    "    # Convert the index to datetime\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    # Calculate daily mean temperature\n",
    "    df_temp_mean = df['te'].resample('D').mean()\n",
    "    # Calculate daily minimum temperature\n",
    "    df_temp_min = df['te'].resample('D').min()\n",
    "    # Calculate daily maximum temperature\n",
    "    df_temp_max = df['te'].resample('D').max()\n",
    "    \n",
    "    # Calculate daily precipitation sum\n",
    "    df_pr_daily = df['pr'].resample('D').sum()\n",
    "    \n",
    "    # Calculate extraterrestrial radiation\n",
    "    lat = -1.071545386681787  # Latitude for calculation\n",
    "    df_ra = Extra_rad(df_temp_max, df_temp_min, df, lat)\n",
    "    df_ra_daily = df_ra.resample('D').mean()\n",
    "    # Concatenate all daily data into a single dataframe\n",
    "    \n",
    "    # Concatenate all daily data into a single dataframe\n",
    "    df_daily = pd.concat([df_pr_daily, df_temp_mean, df_temp_max, df_temp_min, df_ra_daily], axis=1)\n",
    "    \n",
    "    # Rename columns\n",
    "    df_daily.columns = ['pr', 'te_mean', 'te_max', 'te_min', 'ra_mean']\n",
    "    \n",
    "    return df_daily\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/6366qhx54w16_p3_07s3n5ym0000gn/T/ipykernel_56528/1807254617.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.index = pd.to_datetime(df.index)\n"
     ]
    },
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: TA00023, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Process each dataframe in the dictionary\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, df \u001b[38;5;129;01min\u001b[39;00m dataframes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m      \u001b[38;5;66;03m# Process the dataframe and update it in the dictionary\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     dataframes[key] \u001b[38;5;241m=\u001b[39m process_dataframe(df)\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mprocess_dataframe\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_dataframe\u001b[39m(df):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Convert the index to datetime\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Calculate daily mean temperature\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     df_temp_mean \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1059\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(arg, cache_array, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1059\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(arg, \u001b[38;5;28mformat\u001b[39m, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"_maybe_cache\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m         \u001b[38;5;66;03m# \"Union[float, str, datetime, List[Any], Tuple[Any, ...], ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m         \u001b[38;5;66;03m# ndarray[Any, Any], Series]\"; expected \"Union[List[Any], Tuple[Any, ...],\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m         \u001b[38;5;66;03m# Union[Union[ExtensionArray, ndarray[Any, Any]], Index, Series], Series]\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:455\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 455\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    456\u001b[0m     arg,\n\u001b[1;32m    457\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m    458\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[1;32m    459\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[1;32m    460\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    461\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    462\u001b[0m )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[0;32m-> 2177\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m tslib\u001b[38;5;241m.\u001b[39marray_to_datetime(\n\u001b[1;32m   2178\u001b[0m     data,\n\u001b[1;32m   2179\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   2180\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[1;32m   2181\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   2182\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[1;32m   2183\u001b[0m )\n\u001b[1;32m   2185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2186\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2187\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:402\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:551\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:516\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/conversion.pyx:557\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/parsing.pyx:329\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/parsing.pyx:658\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: TA00023, at position 0"
     ]
    }
   ],
   "source": [
    "# Process each dataframe in the dictionary\n",
    "for key, df in dataframes.items():\n",
    "     # Process the dataframe and update it in the dictionary\n",
    "    dataframes[key] = process_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = dataframes['TA00023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), sharex=True, gridspec_kw={'height_ratios': [2, 1, 1]})\n",
    "\n",
    "# Plot lines for mean, min, and max temperature in the first subplot\n",
    "axs[0].plot(df_station.index, df_station['te_mean'], label='Mean temperature')\n",
    "axs[0].plot(df_station.index, df_station['te_min'], label='Min temperature')\n",
    "axs[0].plot(df_station.index, df_station['te_max'], label='Max temperature')\n",
    "axs[0].set_ylabel('Temperature (Â°C)')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot a bar graph for precipitation in the second subplot\n",
    "axs[1].bar(df_station.index, df_station['pr'], width=0.4, align='center', label='Precipitation', color='blue')\n",
    "axs[1].set_ylabel('Precipitation (mm)')\n",
    "axs[1].legend()\n",
    "\n",
    "# Plot a line graph for radiation mean in the third subplot\n",
    "axs[2].plot(df_station.index, df_station['ra_mean'], label='Radiation mean', color='orange')\n",
    "axs[2].set_ylabel('Radiation (W/mÂ²)')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding metadeta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'metadata_TAHMO.txt')) as f: \n",
    "    metadata_tahmo = f.read() \n",
    "    metadata_tahmo = json.loads(metadata_tahmo) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(dict(metadata_tahmo)))\n",
    "\n",
    "location_name_tahmo = []\n",
    "for key, value in metadata_tahmo.items():\n",
    "    if key.startswith('TA'):\n",
    "        location = value.get('location', {})\n",
    "        name = location.get('name')\n",
    "        longitude = location.get('longitude')\n",
    "        latitude = location.get('latitude')\n",
    "        if name and longitude is not None and latitude is not None:\n",
    "            location_name_tahmo.append([key, longitude, latitude])\n",
    "            \n",
    "\n",
    "df_tahmo = pd.DataFrame(location_name_tahmo)\n",
    "df.columns = ['name', 'longitude', 'latitude']\n",
    "df_tahmo.to_csv(os.path.join(data_path, 'location_data.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the GeoDataFrame if interested \n",
    "plotting = False \n",
    "if plotting == True:\n",
    "    geometry = [Point(lon, lat) for name, lon, lat in location_name_tahmo]\n",
    "    points_df = gpd.GeoDataFrame(location_name_tahmo, columns=['name', 'longitude', 'latitude'], geometry= geometry)\n",
    "    # Convert 'longitude' and 'latitude' columns to numeric values\n",
    "    points_df['longitude'] = pd.to_numeric(points_df['longitude'])\n",
    "    points_df['latitude'] = pd.to_numeric(points_df['latitude'])\n",
    "    # Create a geometry column using longitude and latitude\n",
    "    points_df['geometry'] = gpd.points_from_xy(points_df['longitude'], points_df['latitude'])\n",
    "    \n",
    "    points_df.plot()\n",
    "    plt.title('Available TAHMO stations')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oudin_evap(df):\n",
    "    # Mean daily temperature [C]\n",
    "    Ta = df['te_mean'] \n",
    "\n",
    "    # Extra terrestial radiation [MJ/m2/day]\n",
    "    Re = df['ra_mean']\n",
    "\n",
    "    # latent heat flux [MJ/kg]\n",
    "    lam = 2.45 \n",
    "    \n",
    "    # water density [kg/m3]\n",
    "    rho = 1000\n",
    "    \n",
    "    # Calculate Pe\n",
    "    Pe = np.where(Ta + 5 > 0, (Re / (lam * rho)) * (Ta + 5) / 100, 0)\n",
    "    \n",
    "    return Pe   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the evaportaion to the dataframes in the dictionary\n",
    "for key, df in dataframes.items():\n",
    "    # Calculate Pe for the current dataframe\n",
    "    df['pe'] = Oudin_evap(df)\n",
    "\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['TA00130']['pe'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
