{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2af79c2",
   "metadata": {},
   "source": [
    "## Average Evaporation calculation\n",
    "This simple notebook takes in a Kriging interpolated NetCDF file and uses that to calculate the time averaged and spatial averaged evaporation values. THis has previously been demonstrated to create acceptably accurate results to estimate the actual evaporation values in certain areas. For more information we would like to refer you to our report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b5e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "import pathlib\n",
    "import platform \n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2db61bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first entry is pointing to /Users/matskerver/Documents/data_tana/TAHMO/raw_TAHMO, the second one to /Users/matskerver/Documents/data_tana/TAHMO/processed_TAHMO and the third one to /Users/matskerver/Documents/data_tana/TAHMO/interpolated_TAHMO. Animations will be put located in /Users/matskerver/Documents/data_tana/TAHMO/results\n"
     ]
    }
   ],
   "source": [
    "# If errors occur here please refer to the readme file or to the file_imports.py folders. \n",
    "\n",
    "cwd = pathlib.Path().resolve()\n",
    "src = cwd.parent\n",
    "data = src.parent.parent.parent\n",
    "root = src.parent\n",
    "OS_type = platform.system()\n",
    "sys.path.append(str(src))\n",
    "sys.path.append(str(root))\n",
    "from utils.file_imports import *\n",
    "\n",
    "\n",
    "data_paths = file_paths(root, TAHMO = True)\n",
    "raw_files = data_paths[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a59ec4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calculating the mean of the entire dataset after incorrect values are removed. \n",
    "\n",
    "def calculate_evaporation_average(ds):\n",
    "    average_evap = ds_trim['evap'].mean().values\n",
    "    return average_evap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6596ce4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The used dataset contained 525 timestamps with potential invalid data.\n",
      "It contained 1666 timestamps where no anomalies were detected.\n",
      "Proceeding to remove these values...\n",
      "Removed 525 values correctly, checking new dataset...\n",
      "No negative values detected, proceeding to average evaporation value\n",
      "Completed. The average evaporation data for this dataset is 0.41639290443606647mm/day\n"
     ]
    }
   ],
   "source": [
    "# This cell cleans up the Kriging interpolation data as some NaN values were still present in the TAHMO data. \n",
    "# As the evaporation is averaged in time and space it is not needed to have all the datapoints. So this cell\n",
    "# removes any timestep with NaN values and then calculates the average of the timesteps that remain. \n",
    "\n",
    "\n",
    "# Open the kriging NetCDF file and define neccesary variables. Max file size netcdf_file = 4Gb. \n",
    "netcdf_file = 'kriging_results_evap.nc'\n",
    "ds = xr.open_dataset(os.path.join(raw_files, netcdf_file))\n",
    "\n",
    "variable = 'evap'\n",
    "file_paths = []\n",
    "cleaning = True\n",
    "\n",
    "while cleaning: \n",
    "    \n",
    "    time_indices = range(0, ds.dims['time'], 1)  \n",
    "    yes = 0\n",
    "    no = 0\n",
    "    timestamps = []\n",
    "    \n",
    "    for time_index in time_indices: #We loop through all the timesteps and check them individually\n",
    "        selected_data = ds.isel(time=time_index)\n",
    "        data_array = selected_data[variable]\n",
    "\n",
    "        # Both negative and NaN values indicate potential problems in the data and are detected here\n",
    "        nan_check = data_array.isnull()\n",
    "        negative_check = data_array < 0\n",
    "        has_nan = nan_check.any()\n",
    "        has_negative = negative_check.any()\n",
    "\n",
    "        # If any anomoly is detected it is added to the list of values to be removed\n",
    "        if has_nan.values or has_negative.values:\n",
    "            timestamps.append(time_index)\n",
    "            yes += 1\n",
    "        else: \n",
    "            no += 1\n",
    "    \n",
    "    if (yes == 0):\n",
    "        # When no more potential issues are detected in the file we can proceed to calculate the average value\n",
    "        \n",
    "        cleaning = False\n",
    "        print(f'No negative values detected, proceeding to average evaporation value')\n",
    "        average_evap = calculate_evaporation_average(ds)\n",
    "        print(f'Completed. The average evaporation data for this dataset is {average_evap}mm/day')\n",
    "        break;\n",
    "        \n",
    "        \n",
    "    print(f'The used dataset contained {yes} timestamps with potential invalid data.')\n",
    "    print(f'It contained {no} timestamps where no anomalies were detected.')\n",
    "    print('Proceeding to remove these values...')\n",
    "\n",
    "    #A mask is created containing all the timesteps that don't contain NaN values. They are then selected and \n",
    "    #all the other steps are removed from the dataset. \n",
    "    mask = ~np.isin(range(ds.dims['time']), timestamps)\n",
    "    ds_trim = ds.isel(time=mask)\n",
    "    ds = ds_trim\n",
    "\n",
    "    print(f'Removed {yes} values correctly, checking new dataset...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58914472",
   "metadata": {},
   "source": [
    "In the test case the value can simply be copied over to the dataset compiling script. In any final application the file can simply be saved as a NetCDF or .csv file. Alternatively, the function can be simply put in a separate script and then imported in another notebook. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
